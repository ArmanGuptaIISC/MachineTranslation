{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "       MT5ForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer, MT5TokenizerFast,  MT5Tokenizer\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = \"google/mt5-small\"\n",
    "checkpoint = './pretrained_models/mT5/checkpoint-80125'\n",
    "tokenizer =  MT5Tokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Datasets/tenlgu-hindi/fulldata'\n",
    "hindi = []\n",
    "telugu = []\n",
    "for folder in os.listdir(path):\n",
    "    subpath = os.path.join(path,folder)\n",
    "    for file in os.listdir(subpath):\n",
    "        if file.endswith('.hi'):\n",
    "            # print(file)\n",
    "            with open(os.path.join(subpath, file),'r') as hindifile:\n",
    "                hindi.extend(hindifile.readlines())\n",
    "        elif file.endswith('.te'):\n",
    "            # print(file)\n",
    "            with open(os.path.join(subpath, file),'r') as telugufile:\n",
    "                telugu.extend(telugufile.readlines())\n",
    "    assert len(hindi) == len(telugu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Size : 549409\n"
     ]
    }
   ],
   "source": [
    "def prepareData(hindi, telugu):\n",
    "    size=  len(hindi)\n",
    "    data = []\n",
    "    for i in range(size):\n",
    "        if(len(hindi[i].strip().split()) > 150 or len(telugu[i].strip().split())> 150):continue\n",
    "        data.append({\n",
    "            'id': i,\n",
    "            \"translation\": {\n",
    "                \"hi\": hindi[i].strip(),\n",
    "                \"te\": telugu[i].strip()\n",
    "            }\n",
    "        })\n",
    "    print(f'Total Data Size : {len(data)}')\n",
    "    dataset = datasets.Dataset.from_list(data)\n",
    "    return dataset\n",
    "hi_te_books = prepareData(hindi, telugu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 256\n",
    "max_target_length = 256\n",
    "\n",
    "source_lang = \"hi\"\n",
    "\n",
    "target_lang = \"te\"\n",
    "\n",
    "prefix = \"हिंदी से तेलुगू में अनुवाद करें:\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
    "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c8221a72fa4f499c911e7da8ef9349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/549409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_hi_te_books = hi_te_books.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_hi_te_split = tokenized_hi_te_books.train_test_split(train_size=0.7, shuffle=True, seed = 0)\n",
    "tokenized_hi_te_train = tokenized_hi_te_split['train']\n",
    "tokenized_hi_te_test = tokenized_hi_te_split['test'].train_test_split(train_size=0.5, seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(preds, tuple):\n",
    "\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MT5ForConditionalGeneration.from_pretrained(checkpoint,resume_download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_val = tokenized_hi_te_test['train'].train_test_split(test_size = 0.1)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "\n",
    "    output_dir=\"./pretrained_models/mT5\",\n",
    "\n",
    "    evaluation_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    save_total_limit=15,\n",
    "\n",
    "    num_train_epochs=5,\n",
    "\n",
    "    predict_with_generate=True,\n",
    "\n",
    "    fp16=False,\n",
    "\n",
    "    logging_dir=\"./logs/t5logs_hite\",\n",
    "    \n",
    "    logging_strategy='epoch',\n",
    "    \n",
    "    save_strategy= 'epoch',\n",
    "        \n",
    "    report_to=['tensorboard'],\n",
    "\n",
    "    load_best_model_at_end= True\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "\n",
    "    model=model,\n",
    "\n",
    "    args=training_args,\n",
    "\n",
    "    train_dataset=tokenized_hi_te_train,\n",
    "\n",
    "    eval_dataset=small_val,\n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    data_collator=data_collator,\n",
    "\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "tokenized_hi_te_split, trainer = accelerator.prepare(tokenized_hi_te_split, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "\n",
    "    model=model,\n",
    "\n",
    "    args=training_args,\n",
    "\n",
    "    train_dataset=tokenized_hi_te_train,\n",
    "\n",
    "    eval_dataset=tokenized_hi_te_test['test'],\n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    data_collator=data_collator,\n",
    "\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: translation, id. If translation, id are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 82411\n",
      "  Batch size = 24\n",
      "/raid/home/armangupta/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1360' max='3434' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1360/3434 19:28 < 29:42, 1.16 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.215162754058838,\n",
       " 'eval_bleu': 8.723,\n",
       " 'eval_gen_len': 14.1217,\n",
       " 'eval_runtime': 3401.5515,\n",
       " 'eval_samples_per_second': 24.227,\n",
       " 'eval_steps_per_second': 1.01}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
